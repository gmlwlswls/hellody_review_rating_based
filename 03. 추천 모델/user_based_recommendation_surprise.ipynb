{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset, KNNWithMeans, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import cross_validate\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 및 전처리\n",
    "df = pd.read_csv('../review_rating_hellody.csv', encoding = 'cp949')\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df = df[['user_id', 'movie_id', 'rating']]\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# 평점 범위를 1~10으로 설정\n",
    "# 학습 및 테스트 데이터셋 분리\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "traindata = Dataset.load_from_df(train, reader)\n",
    "testdata = Dataset.load_from_df(test, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 사용자에 대한 영화 추천 함수\n",
    "def get_recommendations(algo, user_id, df, n=20):\n",
    "    # 사용자가 평가하지 않은 영화 목록 생성\n",
    "    user_rated_movies = df[df['user_id'] == user_id]['movie_id'].tolist()\n",
    "    all_movies = df['movie_id'].unique()\n",
    "    unrated_movies = [movie for movie in all_movies if movie not in user_rated_movies]\n",
    "    \n",
    "    # 예상 평점 계산\n",
    "    predictions = [algo.predict(user_id, movie) for movie in unrated_movies]\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True) #예상 평점 기준 정렬\n",
    "    \n",
    "    # 상위 n개의 영화 추천\n",
    "    top_n_recommendations = predictions[:n]\n",
    "    return [(pred.iid, pred.est) for pred in top_n_recommendations] # (영화id, 예상 평점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BaselineOnly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 사용자의 평균 평점과 사용자/항목의 편향을 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score:  2.509871877398696\n",
      "Best parameters:  {'bsl_options': {'method': 'sgd', 'n_epochs': 30, 'reg_u': 10, 'reg_i': 5}}\n"
     ]
    }
   ],
   "source": [
    "from surprise import BaselineOnly\n",
    "\n",
    "# 하이퍼파라미터 그리드 설정\n",
    "param_grid = {\n",
    "    'bsl_options': {\n",
    "        'method': ['als', 'sgd'],\n",
    "        'learning_rate' : [0.01, 0.001]\n",
    "        'n_epochs': [30, 50, 70],\n",
    "        'reg_u': [10, 15],\n",
    "        'reg_i': [5, 10]\n",
    "    }\n",
    "}\n",
    "\n",
    "# GridSearchCV를 사용하여 최적의 하이퍼파라미터 찾기\n",
    "gs = GridSearchCV(BaselineOnly, param_grid, measures=['rmse'], cv=5, n_jobs=-1) # 5-폴드 교차 검증\n",
    "gs.fit(traindata)\n",
    "\n",
    "# 최적의 하이퍼파라미터와 해당 성능 출력\n",
    "print(\"Best RMSE score: \", gs.best_score['rmse'])\n",
    "print(\"Best parameters: \", gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using sgd...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DatasetAutoFolds' object has no attribute 'n_users'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m bsl_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      2\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m      3\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg_u\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m      4\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg_i\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m5\u001b[39m}\n\u001b[0;32m      6\u001b[0m algo \u001b[38;5;241m=\u001b[39m BaselineOnly(bsl_options \u001b[38;5;241m=\u001b[39m bsl_options)\n\u001b[1;32m----> 7\u001b[0m predictions \u001b[38;5;241m=\u001b[39m algo\u001b[38;5;241m.\u001b[39mfit(traindata)\u001b[38;5;241m.\u001b[39mtest(testdata)\n\u001b[0;32m      8\u001b[0m accuracy\u001b[38;5;241m.\u001b[39mrmse(predictions)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\surprise\\prediction_algorithms\\baseline_only.py:34\u001b[0m, in \u001b[0;36mBaselineOnly.fit\u001b[1;34m(self, trainset)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainset):\n\u001b[0;32m     33\u001b[0m     AlgoBase\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m, trainset)\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbu, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_baselines()\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:195\u001b[0m, in \u001b[0;36mAlgoBase.compute_baselines\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimating biases using\u001b[39m\u001b[38;5;124m\"\u001b[39m, method_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbu, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbi \u001b[38;5;241m=\u001b[39m method[method_name](\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbu, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbi\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\surprise\\prediction_algorithms\\optimize_baselines.pyx:66\u001b[0m, in \u001b[0;36msurprise.prediction_algorithms.optimize_baselines.baseline_sgd\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DatasetAutoFolds' object has no attribute 'n_users'"
     ]
    }
   ],
   "source": [
    "bsl_options = {'method' : 'sgd',\n",
    "               'n_epochs' : 30,\n",
    "               'reg_u' : 10,\n",
    "               'reg_i' : 5}\n",
    "\n",
    "algo = BaselineOnly(bsl_options = bsl_options)\n",
    "predictions = algo.fit(traindata).test(testdata)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = algo.traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predictions, columns = ['uid', 'iid', 'rui', 'est', 'details'])\n",
    "df['err'] = abs(df.est - df.rui)\n",
    "\n",
    "best_predictions = df.sort_values(by = 'err')[:10]\n",
    "worst_predictions = df.sort_values(by = 'err')[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score:  2.3767002478046115\n",
      "Best parameters:  {'k': 10, 'sim_options': {'name': 'pearson_baseline', 'user_based': True}}\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, KNNWithMeans\n",
    "\n",
    "# 하이퍼파라미터 그리드 설정\n",
    "param_grid = {\n",
    "    'k': [5, 10, 20, 30, 40, 50],  # 이웃 수\n",
    "    'sim_options': {\n",
    "        'name': ['pearson_baseline'],\n",
    "        'user_based': [True]\n",
    "    }\n",
    "}\n",
    "\n",
    "# GridSearchCV를 사용하여 최적의 하이퍼파라미터 찾기\n",
    "gs = GridSearchCV(KNNWithMeans, param_grid, measures=['rmse'], cv=5, n_jobs=-1) # 5-폴드 교차 검증\n",
    "gs.fit(traindata)\n",
    "\n",
    "# 최적의 하이퍼파라미터와 해당 성능 출력\n",
    "print(\"Best RMSE score: \", gs.best_score['rmse'])\n",
    "print(\"Best parameters: \", gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Item-based Model : Test Set\n",
      "RMSE: 2.8523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.8523430209193466"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN 모델 학습\n",
    "algo = KNNWithMeans(k=30, sim_options={'name': 'pearson_baseline', 'user_based': True})\n",
    "algo.fit(trainset)\n",
    "\n",
    "# 테스트 데이터셋으로 예측 및 RMSE 계산\n",
    "test_pred = algo.test(testset)\n",
    "print(\"Item-based Model : Test Set\")\n",
    "accuracy.rmse(test_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추천된 영화 목록:\n",
      "영화 ID: 100015, 예상 평점: 10\n",
      "영화 ID: 10002, 예상 평점: 10\n",
      "영화 ID: 100021, 예상 평점: 10\n",
      "영화 ID: 100022, 예상 평점: 10\n",
      "영화 ID: 100023, 예상 평점: 10\n",
      "영화 ID: 100026, 예상 평점: 10\n",
      "영화 ID: 10003, 예상 평점: 10\n",
      "영화 ID: 100039, 예상 평점: 10\n",
      "영화 ID: 10004, 예상 평점: 10\n",
      "영화 ID: 100041, 예상 평점: 10\n",
      "영화 ID: 10005, 예상 평점: 10\n",
      "영화 ID: 10006, 예상 평점: 10\n",
      "영화 ID: 100069, 예상 평점: 10\n",
      "영화 ID: 10007, 예상 평점: 10\n",
      "영화 ID: 100075, 예상 평점: 10\n",
      "영화 ID: 10008, 예상 평점: 10\n",
      "영화 ID: 100084, 예상 평점: 10\n",
      "영화 ID: 100086, 예상 평점: 10\n",
      "영화 ID: 100087, 예상 평점: 10\n",
      "영화 ID: 10009, 예상 평점: 10\n"
     ]
    }
   ],
   "source": [
    "# 사용자 ID에 대한 추천 영화 목록 출력\n",
    "user_id = 2  \n",
    "recommended_movies = get_recommendations(algo, user_id, df, n=20)\n",
    "print(\"추천된 영화 목록:\")\n",
    "for movie_id, est_rating in recommended_movies:\n",
    "    print(f\"영화 ID: {movie_id}, 예상 평점: {est_rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNBaseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### knnbaseline - gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score:  2.3177131267240956\n",
      "Best parameters:  {'k': 30, 'sim_options': {'name': 'pearson_baseline', 'user_based': True}, 'bsl_options': {'method': 'sgd', 'n_epochs': 40, 'reg_u': 10, 'reg_i': 5}}\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, KNNBaseline\n",
    "\n",
    "# 하이퍼파라미터 그리드 설정\n",
    "param_grid = {\n",
    "    'k': [5, 10, 20, 30, 40, 50],  # 이웃 수\n",
    "    'sim_options': {\n",
    "        'name': ['pearson_baseline'],\n",
    "        'user_based': [True]\n",
    "    },\n",
    "    'bsl_options': {\n",
    "        'method': ['als', 'sgd'],\n",
    "        'n_epochs': [30, 40, 50, 60],\n",
    "        'reg_u': [10, 15],\n",
    "        'reg_i': [5, 10]\n",
    "    }\n",
    "}\n",
    "\n",
    "# GridSearchCV를 사용하여 최적의 하이퍼파라미터 찾기\n",
    "gs = GridSearchCV(KNNBaseline, param_grid, measures=['rmse'], cv=5, n_jobs=-1) # 5-폴드 교차 검증\n",
    "gs.fit(traindata)\n",
    "\n",
    "# 최적의 하이퍼파라미터와 해당 성능 출력\n",
    "print(\"Best RMSE score: \", gs.best_score['rmse'])\n",
    "print(\"Best parameters: \", gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Item-based Model : Test Set\n",
      "RMSE: 2.2759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.2758626961102832"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options = {'name': 'pearson_baseline', 'user_based': True}\n",
    "bsl_options = {'method': 'sgd', 'n_epochs': 40, 'reg_u': 10, 'reg_i': 5}\n",
    "algo = KNNBaseline(k=30, sim_options=sim_options, bsl_options=bsl_options)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# 테스트 데이터셋으로 예측 및 RMSE 계산\n",
    "test_pred = algo.test(testset)\n",
    "print(\"Item-based Model : Test Set\")\n",
    "accuracy.rmse(test_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추천된 영화 목록:\n",
      "영화 ID: 10016, 예상 평점: 10\n",
      "영화 ID: 10038, 예상 평점: 10\n",
      "영화 ID: 100399, 예상 평점: 10\n",
      "영화 ID: 10058, 예상 평점: 10\n",
      "영화 ID: 100610, 예상 평점: 10\n",
      "영화 ID: 10072, 예상 평점: 10\n",
      "영화 ID: 100825, 예상 평점: 10\n",
      "영화 ID: 10002, 예상 평점: 9.965172679776229\n",
      "영화 ID: 100398, 예상 평점: 9.889670124706875\n",
      "영화 ID: 10048, 예상 평점: 9.88064651722792\n",
      "영화 ID: 10028, 예상 평점: 9.827168473624713\n",
      "영화 ID: 10035, 예상 평점: 9.808704918333367\n",
      "영화 ID: 10006, 예상 평점: 9.760100933553552\n",
      "영화 ID: 10020, 예상 평점: 9.751880166464144\n",
      "영화 ID: 10018, 예상 평점: 9.748104958748288\n",
      "영화 ID: 100619, 예상 평점: 9.746221374804085\n",
      "영화 ID: 10047, 예상 평점: 9.71933728626436\n",
      "영화 ID: 10046, 예상 평점: 9.719129491212529\n",
      "영화 ID: 10021, 예상 평점: 9.71906072757728\n",
      "영화 ID: 10005, 예상 평점: 9.705452394657641\n"
     ]
    }
   ],
   "source": [
    "# 사용자 ID에 대한 추천 영화 목록 출력\n",
    "user_id = 2  \n",
    "recommended_movies = get_recommendations(algo, user_id, df, n=20)\n",
    "print(\"추천된 영화 목록:\")\n",
    "for movie_id, est_rating in recommended_movies:\n",
    "    print(f\"영화 ID: {movie_id}, 예상 평점: {est_rating}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
