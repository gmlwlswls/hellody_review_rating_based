{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 사용자 기반 추천시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  movie_id  scaled_rating\n",
      "0            1       100       4.111111\n",
      "1            2       100       2.777778\n",
      "2            3       100       5.000000\n",
      "3            4       100       3.666667\n",
      "4            5       100       5.000000\n",
      "...        ...       ...            ...\n",
      "26416     2201        99       3.222222\n",
      "26417     8454        99       3.222222\n",
      "26418    13022        99       1.000000\n",
      "26419     2419        99       5.000000\n",
      "26420       88        99       1.000000\n",
      "\n",
      "[26421 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_corredspond = pd.read_csv('../df_correspond.csv', encoding= 'cp949') #26421\n",
    "\n",
    "df_total = pd.read_csv('../df_total.csv', encoding= 'cp949') #26421\n",
    "print(df_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_recommendations(algo, user_movie_rating_df, user_id, n=20):\n",
    "    # 모든 영화 목록\n",
    "    all_movie_ids = user_movie_rating_df['movie_id'].unique()\n",
    "    \n",
    "    # 사용자가 이미 본 영화 목록\n",
    "    seen_movie_ids = user_movie_rating_df[user_movie_rating_df['user_id'] == user_id]['movie_id'].unique()\n",
    "    \n",
    "    # 사용자가 보지 않은 영화 목록\n",
    "    unseen_movie_ids = [movie_id for movie_id in all_movie_ids if movie_id not in seen_movie_ids]\n",
    "    \n",
    "    # 사용자가 보지 않은 영화들에 대한 예측 평점 계산\n",
    "    predictions = [algo.predict(user_id, movie_id) for movie_id in unseen_movie_ids]\n",
    "    \n",
    "    # 예측 평점이 높은 순으로 정렬하여 상위 n개 영화 추천\n",
    "    top_n_predictions = sorted(predictions, key=lambda x: x.est, reverse=True)[:n]\n",
    "    \n",
    "    # 추천 영화 ID 리스트 추출\n",
    "    top_n_movie_ids = [pred.iid for pred in top_n_predictions]\n",
    "    \n",
    "    return top_n_movie_ids\n",
    "\n",
    "# # 사용자에게 영화 추천하기\n",
    "# user_id = 1  # 추천을 받을 사용자의 ID\n",
    "# num_recommendations = 20  # 추천할 영화의 수\n",
    "# recommended_movie_ids = get_top_n_recommendations(algo, user_id, num_recommendations)\n",
    "# print(\"사용자에게 추천할 영화 ID 리스트:\", recommended_movie_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, Dataset, Reader, accuracy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 일치하는 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x2d96f4b9550>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_movie_rating_df = df_corredspond[['user_id', 'movie_id', 'rating']]\n",
    "\n",
    "r_min = user_movie_rating_df['rating'].min()\n",
    "r_max = user_movie_rating_df['rating'].max()\n",
    "reader = Reader(rating_scale = (r_min, r_max))\n",
    "data = Dataset.load_from_df(user_movie_rating_df[['user_id', 'movie_id', 'rating']], reader)\n",
    "\n",
    "trainset = data.build_full_trainset()\n",
    "testset = trainset.build_testset()\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "##trainset으로 SVD 학습\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.1230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.12296349734107"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = algo.test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 그리드 탐색을 통한 최적의 파라미터 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###################\n",
      "Best Score : 3.3691135952181432\n",
      "Best Parameters : {'n_factors': 75, 'lr_all': 0.05, 'reg_all': 0.04}\n",
      "#####################\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_factors': [50, 75], 'lr_all': [0.5, 0.05], 'reg_all': [0.06, 0.04]} \n",
    "gs = GridSearchCV(algo_class=SVD, measures=['RMSE'], param_grid=param_grid) \n",
    "gs.fit(data) \n",
    "print('\\n###################') \n",
    "print('Best Score :', gs.best_score['rmse']) \n",
    "print('Best Parameters :', gs.best_params['rmse']) \n",
    "print('#####################')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 최적의 파라미터로 최종 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06514018212962794"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = gs.best_params['rmse']\n",
    "\n",
    "final_algo = SVD(n_factors = best_params['n_factors'], lr_all = best_params['lr_all'], reg_all = best_params['reg_all'])\n",
    "\n",
    "# svd 학습\n",
    "final_algo.fit(trainset)\n",
    "\n",
    "# 최종 모델로 RMSE 측정\n",
    "predictions = final_algo.test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.0, 7.0, 6.0, 8.0, 5.0, 10.0, 3.0, 4.0, 1.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame(predictions)\n",
    "a = predictions_df.r_ui.unique().tolist()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자가 평가하지 않은 영화 중에서 예측 평점이 가장 높은 영화를 추천하는 함수\n",
    "def get_recommendations(predictions_df, user_id, top_n=20):\n",
    "    # 해당 사용자의 예측 평점 데이터 추출\n",
    "    user_predictions = predictions_df[predictions_df['uid'] == user_id]\n",
    "    \n",
    "    # 이미 평가한 영화를 제외한 예측 평점 데이터\n",
    "    user_predictions = user_predictions[user_predictions['r_ui'] == 0]\n",
    "    \n",
    "    # 예측 평점이 높은 순서대로 정렬\n",
    "    user_predictions = user_predictions.sort_values(by='est', ascending=False)\n",
    "    \n",
    "    # 상위 N개의 추천 영화 반환\n",
    "    return user_predictions.head(top_n)\n",
    "\n",
    "# 예시: 사용자 '1'에게 추천할 상위 5개의 영화 출력\n",
    "user_id = '1'  # 사용자 ID\n",
    "recommended_movies = get_recommendations(predictions_df, user_id, top_n=5)\n",
    "\n",
    "print(f\"Recommended movies for user {user_id}:\")\n",
    "print(recommended_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x2d969b0b710>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_movie_rating_match = df_match[['user_id', 'movie_id', 'rating']]\n",
    "\n",
    "r_min_match = user_movie_rating_match['rating'].min()\n",
    "r_max_match = user_movie_rating_match['rating'].max()\n",
    "reader = Reader(rating_scale = (r_min_match, r_max_match))\n",
    "data_match = Dataset.load_from_df(user_movie_rating_match[['user_id', 'movie_id', 'rating']], reader)\n",
    "\n",
    "trainset_match = data.build_full_trainset()\n",
    "testset_match = trainset.build_testset()\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "##trainset으로 SVD 학습\n",
    "algo.fit(trainset_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.1258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.125821213550905"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_match = algo.test(testset_match)\n",
    "accuracy.rmse(predictions_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###################\n",
      "Best Score : 3.3719792179671644\n",
      "Best Parameters : {'n_factors': 50, 'lr_all': 0.05, 'reg_all': 0.04}\n",
      "#####################\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV, cross_validate\n",
    "\n",
    "param_grid = {'n_factors': [50, 75], 'lr_all': [0.5, 0.05], 'reg_all': [0.06, 0.04]} \n",
    "gs = GridSearchCV(algo_class=SVD, measures=['RMSE'], param_grid=param_grid) \n",
    "gs.fit(data) \n",
    "print('\\n###################') \n",
    "print('Best Score :', gs.best_score['rmse']) \n",
    "print('Best Parameters :', gs.best_params['rmse']) \n",
    "print('#####################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06502611469043694"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = gs.best_params['rmse']\n",
    "\n",
    "final_algo = SVD(n_factors = best_params['n_factors'], lr_all = best_params['lr_all'], reg_all = best_params['reg_all'])\n",
    "\n",
    "# svd 학습\n",
    "final_algo.fit(trainset_match)\n",
    "\n",
    "# 최종 모델로 RMSE 측정\n",
    "predictions_match = final_algo.test(testset_match)\n",
    "accuracy.rmse(predictions_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>r_ui</th>\n",
       "      <th>est</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4619</td>\n",
       "      <td>35839</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.937129</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1576</td>\n",
       "      <td>10874</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.936087</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1576</td>\n",
       "      <td>27051</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.943775</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1576</td>\n",
       "      <td>66046</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.006797</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1576</td>\n",
       "      <td>17806</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.891670</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>30187</td>\n",
       "      <td>46415</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.058096</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>18798</td>\n",
       "      <td>23093</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.913468</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>3077</td>\n",
       "      <td>10201</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.936756</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>10632</td>\n",
       "      <td>101960</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.066922</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>12161</td>\n",
       "      <td>98141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.058297</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid     iid  r_ui       est                    details\n",
       "0       4619   35839   9.0  8.937129  {'was_impossible': False}\n",
       "1       1576   10874   7.0  6.936087  {'was_impossible': False}\n",
       "2       1576   27051   7.0  6.943775  {'was_impossible': False}\n",
       "3       1576   66046   6.0  6.006797  {'was_impossible': False}\n",
       "4       1576   17806   8.0  7.891670  {'was_impossible': False}\n",
       "...      ...     ...   ...       ...                        ...\n",
       "14995  30187   46415   1.0  1.058096  {'was_impossible': False}\n",
       "14996  18798   23093  10.0  9.913468  {'was_impossible': False}\n",
       "14997   3077   10201  10.0  9.936756  {'was_impossible': False}\n",
       "14998  10632  101960   1.0  1.066922  {'was_impossible': False}\n",
       "14999  12161   98141   1.0  1.058297  {'was_impossible': False}\n",
       "\n",
       "[15000 rows x 5 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(predictions_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNWithMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from surprise import KNNWithMeans\n",
    "\n",
    "# user_movie_rating = df[['user_id', 'movie_id', 'rating']]\n",
    "# user_movie_rating_match = df_match[['user_id', 'movie_id', 'rating']]\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_df, test_df = train_test_split(user_movie_rating, test_size=0.2)\n",
    "# train_df_match, test_df_match = train_test_split(user_movie_rating_match, test_size=0.2)\n",
    "\n",
    "# sim_options = {\n",
    "#   \"name\" : \"pearson\" ,\n",
    "#   \"user_based\" : True \n",
    "# }\n",
    "# algo = KNNWithMeans(sim_options= sim_options)\n",
    "\n",
    "# from surprise import Dataset, Reader\n",
    "# from surprise import accuracy\n",
    "# from surprise.model_selection import train_test_split\n",
    "\n",
    "# # Rating의 범위를 지정하여 데이터 리더를 생성합니다.\n",
    "# reader = Reader(rating_scale=(1, 10))\n",
    "\n",
    "# trainset = Dataset.load_from_df(train_df[['user_id', 'movie_id', 'rating']], reader).build_full_trainset()\n",
    "# testset = Dataset.load_from_df(test_df[['user_id', 'movie_id', 'rating']], reader).build_full_trainset().build_testset()\n",
    "\n",
    "# trainset_match = Dataset.load_from_df(train_df_match[['user_id', 'movie_id', 'rating']], reader).build_full_trainset()\n",
    "# testset_match = Dataset.load_from_df(test_df_match[['user_id', 'movie_id', 'rating']], reader).build_full_trainset().build_testset()\n",
    "\n",
    "# # 전체 데이터에 대한 예측 및 평가\n",
    "# algo.fit(trainset)\n",
    "# predictions_full = algo.test(testset)\n",
    "# accuracy.rmse(predictions_full) #3.8395\n",
    "\n",
    "# # 일치 데이터에 대한 예측 및 평가\n",
    "# algo.fit(trainset_match)\n",
    "# predictions_match = algo.test(testset_match)\n",
    "# accuracy.rmse(predictions_match) #3.9464\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
