{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset, KNNWithMeans, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text) :\n",
    "  hangul = re.compile('[^ ㄱ-ㅣ가-힣]+')\n",
    "  result = hangul.sub('', text)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "\n",
    "def get_token(x) :\n",
    "  tokenized_sentence = okt.morphs(x, stem = True) # 토큰화\n",
    "  stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
    "  return stopwords_removed_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id       0\n",
      "movie_id      0\n",
      "rating        0\n",
      "ko_review    64\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22212\\1068905852.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['ko_review'].replace('', np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드 및 전처리\n",
    "df = pd.read_csv('../review_rating_hellody.csv', encoding = 'cp949')\n",
    "df.dropna(axis= 0, how= 'any', inplace= True)\n",
    "\n",
    "df['ko_review'] = df['review'].apply(lambda x : text_cleaning(x))\n",
    "del df['review']\n",
    "\n",
    "df['ko_review'] = df['ko_review'].str.replace('^ +', \"\") # white space 데이터를 empty value로 변경\n",
    "df['ko_review'].replace('', np.nan, inplace=True)\n",
    "print(df.isnull().sum()) #64\n",
    "df.dropna(axis= 0, how= 'any', inplace= True)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  movie_id  rating  \\\n",
      "0            1       100       8   \n",
      "1            2       100       5   \n",
      "2            3       100      10   \n",
      "3            4       100       7   \n",
      "4            5       100      10   \n",
      "...        ...       ...     ...   \n",
      "26517     2201        99       6   \n",
      "26518     8454        99       6   \n",
      "26519    13022        99       1   \n",
      "26520     2419        99      10   \n",
      "26521       88        99       1   \n",
      "\n",
      "                                               ko_review  \n",
      "0      [다니엘, 크다, 레이, 그, 블루, 컬러, 연기, 훌륭하다, 얌전하다, 고양이, ...  \n",
      "1      [사랑, 눈, 을, 뜨다, 살다, 음, 을, 느끼다, 노년, 엄마, 이야기, 중반,...  \n",
      "2                          [자연, 그대, 데려가다, 눈물, 방울, 로, 외면]  \n",
      "3      [나이, 먹다, 인간, 본능, 살, 아, 있다, 젊음, 늙음, 도시, 시골, 현재,...  \n",
      "4      [내, 엄마, 이야기, 로, 나아가다, 훗날, 내, 이야기, 로, 상상, 보다, 되...  \n",
      "...                                                  ...  \n",
      "26517                              [신약, 이해, 안되다, 살인, 방법]  \n",
      "26518                                       [어이, 없다, 내용]  \n",
      "26519                [일본애니, 똑같다, 스토리, 범인, 까지, 한국영, 화, 뭐]  \n",
      "26520  [박해일, 때문, 점, 주다, 근데, 진짜, 시나리오, 발로썻, 나, 하나, 부터,...  \n",
      "26521                                      [잃다, 만들다, 영화]  \n",
      "\n",
      "[26421 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df['ko_review'] = df['ko_review'].apply(get_token) #10만개 32m 52.3s / 5만개 16m 52.9s\n",
    "\n",
    "drop_train = [index for index, sentence in enumerate(df['ko_review']) if len(sentence) < 1]\n",
    "len(drop_train) #\n",
    "\n",
    "df.drop(index= drop_train, axis= 0, inplace= True)\n",
    "print(df) #\n",
    "\n",
    "# 토크나이저 불러오기\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "# 테스트 데이터 전처리 및 토크나이저 적용\n",
    "X = tokenizer.texts_to_sequences(df['ko_review'])\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size #\n",
    "\n",
    "X = pad_sequences(X, maxlen= 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,  8654,   209,    11],\n",
       "       [    0,     0,     0, ...,  2200,   120,   347],\n",
       "       [    0,     0,     0, ...,  5332,    16,  2873],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,   496,   231,    58],\n",
       "       [    0,     0,     0, ...,    63,    11, 17176],\n",
       "       [    0,     0,     0, ...,   904,    23,     1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,957,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │     \u001b[38;5;34m3,957,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m117,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,150,356</span> (31.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,150,356\u001b[0m (31.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,075,177</span> (15.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,075,177\u001b[0m (15.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,075,179</span> (15.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m4,075,179\u001b[0m (15.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 저장된 모델 로드\n",
    "loaded_model = load_model('best_model_LSTM_30.keras')\n",
    "\n",
    "# 로드한 모델로 예측 수행\n",
    "predictions = loaded_model.predict(X)\n",
    "\n",
    "# 모델 요약 정보 출력\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5662551 ]\n",
      " [0.21420896]\n",
      " [0.9278456 ]\n",
      " ...\n",
      " [0.0683458 ]\n",
      " [0.2641374 ]\n",
      " [0.12170036]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions) #26421"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>ko_review</th>\n",
       "      <th>model_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>[다니엘, 크다, 레이, 그, 블루, 컬러, 연기, 훌륭하다, 얌전하다, 고양이, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>[자연, 그대, 데려가다, 눈물, 방울, 로, 외면]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>[나이, 먹다, 인간, 본능, 살, 아, 있다, 젊음, 늙음, 도시, 시골, 현재,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>[내, 엄마, 이야기, 로, 나아가다, 훗날, 내, 이야기, 로, 상상, 보다, 되...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>[공감, 반감, 을, 동시, 부르다]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26505</th>\n",
       "      <td>13020</td>\n",
       "      <td>99</td>\n",
       "      <td>10</td>\n",
       "      <td>[끝, 급, 마무리, 되다, 늘다, 되다, 생각, 바보, 연기, 진짜, 쩔다]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26507</th>\n",
       "      <td>150</td>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>[그럭저럭, 괜찮다, 긴장감, 추리]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26509</th>\n",
       "      <td>1359</td>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>[처음, 부터, 마지막, 까지, 긴장감, 있다, 내, 용구성]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26512</th>\n",
       "      <td>1185</td>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>[영화, 전체, 적, 분위기, 좋다, 쌩뚱맞, 인과관계, 쫌]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26516</th>\n",
       "      <td>3356</td>\n",
       "      <td>99</td>\n",
       "      <td>10</td>\n",
       "      <td>[왜, 평점, 모양, 이지, 나, 뒤, 오다, 반전, 완전, 쩔다, 해일이, 짱, 인데]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18528 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating  \\\n",
       "0            1       100       8   \n",
       "2            3       100      10   \n",
       "3            4       100       7   \n",
       "4            5       100      10   \n",
       "10          11       100       7   \n",
       "...        ...       ...     ...   \n",
       "26505    13020        99      10   \n",
       "26507      150        99       6   \n",
       "26509     1359        99       7   \n",
       "26512     1185        99       7   \n",
       "26516     3356        99      10   \n",
       "\n",
       "                                               ko_review  model_label  \n",
       "0      [다니엘, 크다, 레이, 그, 블루, 컬러, 연기, 훌륭하다, 얌전하다, 고양이, ...            1  \n",
       "2                          [자연, 그대, 데려가다, 눈물, 방울, 로, 외면]            1  \n",
       "3      [나이, 먹다, 인간, 본능, 살, 아, 있다, 젊음, 늙음, 도시, 시골, 현재,...            1  \n",
       "4      [내, 엄마, 이야기, 로, 나아가다, 훗날, 내, 이야기, 로, 상상, 보다, 되...            1  \n",
       "10                                  [공감, 반감, 을, 동시, 부르다]            1  \n",
       "...                                                  ...          ...  \n",
       "26505        [끝, 급, 마무리, 되다, 늘다, 되다, 생각, 바보, 연기, 진짜, 쩔다]            1  \n",
       "26507                               [그럭저럭, 괜찮다, 긴장감, 추리]            1  \n",
       "26509                 [처음, 부터, 마지막, 까지, 긴장감, 있다, 내, 용구성]            1  \n",
       "26512                 [영화, 전체, 적, 분위기, 좋다, 쌩뚱맞, 인과관계, 쫌]            1  \n",
       "26516  [왜, 평점, 모양, 이지, 나, 뒤, 오다, 반전, 완전, 쩔다, 해일이, 짱, 인데]            1  \n",
       "\n",
       "[18528 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 결과를 긍정/부정으로 변환\n",
    "threshold = 0.5\n",
    "predicted_labels = (predictions > threshold).astype(int)\n",
    "\n",
    "# predicted_labels를 데이터프레임의 새로운 열로 추가\n",
    "df['model_label'] = predicted_labels\n",
    "\n",
    "# 결과 출력\n",
    "df[df['model_label'] == 0] #8304\n",
    "df[df['model_label'] == 1] #18117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21897\n",
      "4524\n"
     ]
    }
   ],
   "source": [
    "df['rating'] = df['rating'].astype(float)\n",
    "df['rating_label'] = df['rating'].apply(lambda x: 1 if x > 5 else 0)\n",
    "df\n",
    "\n",
    "positive_ratings = df[df['rating_label'] == 1]\n",
    "negative_ratings = df[df['rating_label'] == 0]\n",
    "print(len(positive_ratings)) #21897\n",
    "print(len(negative_ratings)) #4524"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>ko_review</th>\n",
       "      <th>model_label</th>\n",
       "      <th>rating_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[다니엘, 크다, 레이, 그, 블루, 컬러, 연기, 훌륭하다, 얌전하다, 고양이, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[사랑, 눈, 을, 뜨다, 살다, 음, 을, 느끼다, 노년, 엄마, 이야기, 중반,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[자연, 그대, 데려가다, 눈물, 방울, 로, 외면]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[나이, 먹다, 인간, 본능, 살, 아, 있다, 젊음, 늙음, 도시, 시골, 현재,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[내, 엄마, 이야기, 로, 나아가다, 훗날, 내, 이야기, 로, 상상, 보다, 되...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26517</th>\n",
       "      <td>2201</td>\n",
       "      <td>99</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[신약, 이해, 안되다, 살인, 방법]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26518</th>\n",
       "      <td>8454</td>\n",
       "      <td>99</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[어이, 없다, 내용]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26519</th>\n",
       "      <td>13022</td>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[일본애니, 똑같다, 스토리, 범인, 까지, 한국영, 화, 뭐]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26520</th>\n",
       "      <td>2419</td>\n",
       "      <td>99</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[박해일, 때문, 점, 주다, 근데, 진짜, 시나리오, 발로썻, 나, 하나, 부터,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26521</th>\n",
       "      <td>88</td>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[잃다, 만들다, 영화]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26421 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating  \\\n",
       "0            1       100     8.0   \n",
       "1            2       100     5.0   \n",
       "2            3       100    10.0   \n",
       "3            4       100     7.0   \n",
       "4            5       100    10.0   \n",
       "...        ...       ...     ...   \n",
       "26517     2201        99     6.0   \n",
       "26518     8454        99     6.0   \n",
       "26519    13022        99     1.0   \n",
       "26520     2419        99    10.0   \n",
       "26521       88        99     1.0   \n",
       "\n",
       "                                               ko_review  model_label  \\\n",
       "0      [다니엘, 크다, 레이, 그, 블루, 컬러, 연기, 훌륭하다, 얌전하다, 고양이, ...            1   \n",
       "1      [사랑, 눈, 을, 뜨다, 살다, 음, 을, 느끼다, 노년, 엄마, 이야기, 중반,...            0   \n",
       "2                          [자연, 그대, 데려가다, 눈물, 방울, 로, 외면]            1   \n",
       "3      [나이, 먹다, 인간, 본능, 살, 아, 있다, 젊음, 늙음, 도시, 시골, 현재,...            1   \n",
       "4      [내, 엄마, 이야기, 로, 나아가다, 훗날, 내, 이야기, 로, 상상, 보다, 되...            1   \n",
       "...                                                  ...          ...   \n",
       "26517                              [신약, 이해, 안되다, 살인, 방법]            0   \n",
       "26518                                       [어이, 없다, 내용]            0   \n",
       "26519                [일본애니, 똑같다, 스토리, 범인, 까지, 한국영, 화, 뭐]            0   \n",
       "26520  [박해일, 때문, 점, 주다, 근데, 진짜, 시나리오, 발로썻, 나, 하나, 부터,...            0   \n",
       "26521                                      [잃다, 만들다, 영화]            0   \n",
       "\n",
       "       rating_label  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "...             ...  \n",
       "26517             1  \n",
       "26518             1  \n",
       "26519             0  \n",
       "26520             1  \n",
       "26521             0  \n",
       "\n",
       "[26421 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df #26421"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(1, 5))\n",
    "df['scaled_rating'] = scaler.fit_transform(df[['rating']])\n",
    "df['scaled_rating'] = df['scaled_rating'].round().astype(int)\n",
    "\n",
    "df_correspond = df[df['rating_label'] == df['model_label']]\n",
    "df_correspond #4524\n",
    "\n",
    "df_discord = df[df['rating_label'] != df['model_label']]\n",
    "df_discord\n",
    "\n",
    "df_total = df[['user_id', 'movie_id', 'scaled_rating']]\n",
    "df_correspond = df_correspond[['user_id', 'movie_id', 'scaled_rating']]\n",
    "df_discord = df_discord[['user_id', 'movie_id', 'scaled_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total, test_total = train_test_split(df_total, test_size=0.2, random_state=42)\n",
    "train_correspond, test_correspond = train_test_split(df_correspond, test_size=0.2, random_state=42)\n",
    "train_discord, test_discord = train_test_split(df_discord, test_size=0.2, random_state=42)\n",
    "\n",
    "# 평점 범위를 1~10으로 설정\n",
    "# 학습 및 테스트 데이터셋 분리\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "trainset_total = Dataset.load_from_df(train_total, reader)\n",
    "testset_total = Dataset.load_from_df(test_total, reader)\n",
    "\n",
    "trainset_correspond = Dataset.load_from_df(train_correspond, reader)\n",
    "testset_corresopnd = Dataset.load_from_df(test_correspond, reader)\n",
    "\n",
    "trainset_discord = Dataset.load_from_df(train_discord, reader)\n",
    "testset_discord = Dataset.load_from_df(test_discord, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "from surprise import SVD, SVDpp, SlopeOne, NMF, NormalPredictor, KNNBaseline, KNNBasic, KNNWithZScore, BaselineOnly, CoClustering\n",
    "\n",
    "total_result = []\n",
    "for algorithm in [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(),\n",
    "                  KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()] :\n",
    "  results = cross_validate(algorithm, trainset_total, measures = ['RMSE'], cv = 3, verbose = False)\n",
    "\n",
    "  tmp = pd.DataFrame.from_dict(results).mean(axis = 0)\n",
    "  tmp = pd.concat([tmp, pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm'])])\n",
    "  total_result.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 test_rmse  fit_time  test_time\n",
      "Algorithm                                      \n",
      "BaselineOnly      1.161898  0.034319   0.019720\n",
      "SVD               1.167151  0.131195   0.017106\n",
      "SVDpp             1.170497  0.126104   0.044352\n",
      "KNNBaseline       1.242642  0.689675   0.410700\n",
      "CoClustering      1.310165  0.535441   0.019840\n",
      "KNNBasic          1.348666  0.722737   0.299761\n",
      "KNNWithMeans      1.365855  0.748416   0.265357\n",
      "NMF               1.370869  0.412744   0.024205\n",
      "KNNWithZScore     1.372146  0.803122   0.236021\n",
      "SlopeOne          1.383118  0.058611   0.038249\n",
      "NormalPredictor   1.665557  0.012668   0.015458\n"
     ]
    }
   ],
   "source": [
    "total_result_df = pd.DataFrame(total_result).set_index('Algorithm').sort_values('test_rmse')\n",
    "print(total_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "correspond_result = []\n",
    "for algorithm in [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(),\n",
    "                  KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()] :\n",
    "  results = cross_validate(algorithm, trainset_correspond, measures = ['RMSE'], cv = 3, verbose = False)\n",
    "\n",
    "  tmp = pd.DataFrame.from_dict(results).mean(axis = 0)\n",
    "  tmp = pd.concat([tmp, pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm'])])\n",
    "  correspond_result.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 test_rmse  fit_time  test_time\n",
      "Algorithm                                      \n",
      "SVD               1.167157  0.109256   0.027129\n",
      "BaselineOnly      1.170130  0.027408   0.028441\n",
      "SVDpp             1.180391  0.094935   0.042588\n",
      "KNNBaseline       1.240084  0.497605   0.221128\n",
      "CoClustering      1.331819  0.590276   0.017996\n",
      "KNNBasic          1.364754  0.473801   0.175846\n",
      "NMF               1.393033  0.336038   0.014308\n",
      "KNNWithZScore     1.406711  0.794781   0.199527\n",
      "KNNWithMeans      1.407666  0.526114   0.214659\n",
      "SlopeOne          1.417719  0.030385   0.024772\n",
      "NormalPredictor   1.684282  0.010850   0.016122\n"
     ]
    }
   ],
   "source": [
    "correspond_result_df = pd.DataFrame(correspond_result).set_index('Algorithm').sort_values('test_rmse')\n",
    "print(correspond_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "discord_result = []\n",
    "for algorithm in [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(),\n",
    "                  KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()] :\n",
    "  results = cross_validate(algorithm, trainset_discord, measures = ['RMSE'], cv = 3, verbose = False)\n",
    "\n",
    "  tmp = pd.DataFrame.from_dict(results).mean(axis = 0)\n",
    "  tmp = pd.concat([tmp, pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm'])])\n",
    "  discord_result.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 test_rmse  fit_time  test_time\n",
      "Algorithm                                      \n",
      "SVDpp             1.168319  0.031871   0.014914\n",
      "BaselineOnly      1.175015  0.005621   0.004044\n",
      "SVD               1.180070  0.031579   0.009812\n",
      "KNNBaseline       1.194557  0.044844   0.099575\n",
      "KNNBasic          1.235492  0.044524   0.091335\n",
      "KNNWithMeans      1.281553  0.065924   0.022283\n",
      "CoClustering      1.286686  0.105441   0.005546\n",
      "KNNWithZScore     1.296439  0.131295   0.024973\n",
      "SlopeOne          1.306815  0.020231   0.009173\n",
      "NMF               1.322802  0.112598   0.010991\n",
      "NormalPredictor   1.613149  0.000000   0.005609\n"
     ]
    }
   ],
   "source": [
    "discord_result_df = pd.DataFrame(discord_result).set_index('Algorithm').sort_values('test_rmse')\n",
    "print(discord_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.to_csv('../df_total.csv', encoding='cp949', index= False)\n",
    "df_correspond.to_csv('../df_correspond.csv', encoding='cp949', index= False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
